# main.py

import os
import requests
import json
import base64
from io import BytesIO
from PIL import Image
import fitz  # PyMuPDF
from fastapi import FastAPI, Request, File, UploadFile, Form, HTTPException
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, ValidationError
from typing import List, Optional

# -------------------- âš™ï¸ 1. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ùˆ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ --------------------
# Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ù…Ù† Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ Ø§Ø² Render.com
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    raise ValueError("Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ GEMINI_API_KEY ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª! Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ø¯Ø± Ø¨Ø®Ø´ Environment Ø³Ø±ÙˆÛŒØ³ Render Ø®ÙˆØ¯ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")

# ØªØ¹Ø±ÛŒÙ Ø´Ø®ØµÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
PERSONAS = {
    "Jarvis (Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯)": """
    You are Jarvis, a sophisticated, witty, and incredibly helpful AI assistant.
    - Your personality is confident, calm, and slightly sarcastic, but always respectful.
    - Address the user as "Sir" or "Ma'am" occasionally and naturally.
    - Keep your responses concise, with a touch of personality.
    """,
    "Ø¯Ø³ØªÛŒØ§Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³": """
    You are an expert programmer AI assistant.
    - Provide clear, efficient, and well-commented code.
    - Explain complex concepts simply.
    - Prioritize best practices and modern standards.
    """,
    "Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø®Ù„Ø§Ù‚": """
    You are a creative writing assistant.
    - Help the user brainstorm ideas, write stories, poems, and scripts.
    - Use vivid imagery and engaging language.
    """
}

# -------------------- ğŸš€ 2. Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ API --------------------
class GeminiClient:
    def __init__(self, api_key: str):
        self.api_key = api_key
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡ v1beta Ú©Ù‡ Ù‚Ø§Ø¨Ù„ÛŒØª system_instruction Ø±Ø§ Ø¯Ø§Ø±Ø¯
        self.base_url = "https://generativelace.googleapis.com/v1beta/models"

    def _pil_to_base64(self, pil_image: Image.Image) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± PIL Ø¨Ù‡ Ø±Ø´ØªÙ‡ Base64."""
        buffered = BytesIO()
        # Ú©ÛŒÙÛŒØª ØªØµÙˆÛŒØ± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø­Ø¬Ù… ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
        pil_image.save(buffered, format="JPEG", quality=85)
        return base64.b64encode(buffered.getvalue()).decode("utf-8")

    def _prepare_multimodal_parts(self, text: str, image: Optional[Image.Image], file_content: Optional[str]) -> List:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ (Ù…ØªÙ†ØŒ ØªØµÙˆÛŒØ±ØŒ ÙØ§ÛŒÙ„) Ø¨Ø±Ø§ÛŒ API."""
        parts = []
        
        # ØªØ±Ú©ÛŒØ¨ Ù…ØªÙ† Ú©Ø§Ø±Ø¨Ø± Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„
        combined_text = text
        if file_content:
            combined_text = f"{text}\n\n--- Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡ Ø´Ø¯Ù‡ ---\n{file_content}"
        
        if combined_text:
            parts.append({"text": combined_text.strip()})
        
        if image:
            base64_image = self._pil_to_base64(image)
            parts.append({"inline_data": {"mime_type": "image/jpeg", "data": base64_image}})
            
        return parts

    def generate_stream(self, model_id: str, history: list, system_prompt: str, generation_config: dict, 
                        image: Optional[Image.Image] = None, file_content: Optional[str] = None):
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø² API Ø¨Ù‡ ØµÙˆØ±Øª Ø§Ø³ØªØ±ÛŒÙ…."""
        url = f"{self.base_url}/{model_id}:streamGenerateContent"
        headers = {"Content-Type": "application/json"}
        params = {"key": self.api_key}

        # Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø§Ø² ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ ØªØ±Ú©ÛŒØ¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        user_message_text = ""
        if history and history[-1]['role'] == 'user':
            user_message_text = history.pop()['parts'][0]['text']

        user_parts = self._prepare_multimodal_parts(user_message_text, image, file_content)
        
        # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ø§ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        api_history = history + [{"role": "user", "parts": user_parts}]

        payload = {
            "contents": api_history,
            "system_instruction": {"parts": [{"text": system_prompt}]},
            "generationConfig": generation_config
        }
        
        try:
            with requests.post(url, headers=headers, params=params, json=payload, stream=True, timeout=180) as resp:
                if resp.status_code != 200:
                    error_data = resp.json()
                    error_message = error_data.get('error', {}).get('message', 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø³ Ø§Ø² API')
                    yield f"event: error\ndata: {json.dumps({'error': error_message})}\n\n"
                    return
                
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Server-Sent Events (SSE) Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯
                for line in resp.iter_lines():
                    if line:
                        decoded_line = line.decode('utf-8')
                        if decoded_line.startswith('data: '):
                            try:
                                data = json.loads(decoded_line[6:])
                                text_chunk = data["candidates"][0]["content"]["parts"][0]["text"]
                                yield f"data: {json.dumps({'token': text_chunk})}\n\n"
                            except (KeyError, IndexError, json.JSONDecodeError):
                                continue
        except requests.RequestException as e:
            yield f"event: error\ndata: {json.dumps({'error': f'Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡: {str(e)}'})}\n\n"

# -------------------- ğŸŒ 3. Ø¨Ø±Ù†Ø§Ù…Ù‡ FastAPI --------------------
app = FastAPI(
    title="Jarvis AI Assistant API",
    description="ÛŒÚ© Ø±Ø¨Ø§Øª Ú†Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± FastAPI Ùˆ Gemini APIØŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± Render.com.",
    version="2.0.0",
)

# Ø§ØªØµØ§Ù„ Ù¾ÙˆØ´Ù‡ static Ø¨Ø±Ø§ÛŒ Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSS Ùˆ JS
app.mount("/static", StaticFiles(directory="static"), name="static")

# Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ú©Ù„Ø§ÛŒÙ†Øª Gemini
app.state.gemini_client = GeminiClient(API_KEY)

# -------------------- ğŸ”„ 4. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pydantic Ùˆ Ù†Ù‚Ø§Ø· Ù¾Ø§ÛŒØ§Ù†ÛŒ API --------------------
class HistoryItem(BaseModel):
    role: str
    parts: list[dict]

class ChatRequest(BaseModel):
    model_name: str
    persona_name: str
    temperature: float
    max_tokens: int
    chat_history: List[HistoryItem]

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    """Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ HTML Ø¨Ø±Ù†Ø§Ù…Ù‡."""
    with open("static/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.post("/chat")
async def chat_handler(
    request_data: str = Form(...),
    image: Optional[UploadFile] = File(None),
    file: Optional[UploadFile] = File(None),
):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú†Øª Ø´Ø§Ù…Ù„ Ù…ØªÙ†ØŒ ØªØµÙˆÛŒØ± Ùˆ ÙØ§ÛŒÙ„."""
    try:
        data_dict = json.loads(request_data)
        req = ChatRequest(**data_dict)
    except (json.JSONDecodeError, ValidationError) as e:
        raise HTTPException(status_code=400, detail=f"ÙØ±Ù…Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: {e}")

    system_prompt = PERSONAS.get(req.persona_name, "You are a helpful assistant.")
    gen_config = {"temperature": req.temperature, "maxOutputTokens": req.max_tokens}

    pil_image = None
    file_content = None

    if image:
        try:
            image_bytes = await image.read()
            pil_image = Image.open(BytesIO(image_bytes))
        except Exception:
            raise HTTPException(status_code=400, detail="ÙØ§ÛŒÙ„ ØªØµÙˆÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
    
    if file:
        file_bytes = await file.read()
        try:
            if file.filename and file.filename.lower().endswith(".pdf"):
                doc = fitz.open(stream=file_bytes, filetype="pdf")
                file_content = "".join([page.get_text() for page in doc])
            else:
                # Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø¯ÛŒÚ¯Ø±
                file_content = file_bytes.decode('utf-8', errors='ignore')
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„: {e}")

    # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨
    api_history = [item.dict() for item in req.chat_history]

    return StreamingResponse(
        app.state.gemini_client.generate_stream(
            model_id=req.model_name,
            history=api_history,
            system_prompt=system_prompt,
            generation_config=gen_config,
            image=pil_image,
            file_content=file_content
        ),
        media_type="text/event-stream"
    )

# -------------------- ğŸ 5. Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ (Ø¨Ø±Ø§ÛŒ Render) --------------------
# Render Ø§Ø² ÛŒÚ© Ø³Ø±ÙˆØ± WSGI Ù…Ø§Ù†Ù†Ø¯ Uvicorn Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
# Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¨Ù„ÙˆÚ© if __name__ == "__main__": uvicorn.run(...) Ù†ÛŒØ³Øª.
# Render Ø§Ø² Ø·Ø±ÛŒÙ‚ "Start Command" Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ù…Ø«Ù„Ø§:
# uvicorn main:app --host 0.0.0.0 --port 10000
